{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransformerModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMIYH4l7PH39s3EKLUcKeok",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sujal-vajire/Machine-learning-models/blob/main/TransformerModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlvqhpOy7V5N",
        "outputId": "31685a2a-25c1-466e-dc3f-f57d3d0eb6d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version: 2.8.2\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "print('Tensorflow version: {}'.format(tf.__version__))\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Time2Vector(Layer):\n",
        "    def __init__(self, seq_len, **kwargs):\n",
        "        super(Time2Vector, self).__init__()\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        '''Initialize weights and biases with shape (batch, seq_len)'''\n",
        "        self.weights_linear = self.add_weight(name='weight_linear',\n",
        "                                              shape=(int(self.seq_len),),\n",
        "                                              initializer='uniform',\n",
        "                                              trainable=True)\n",
        "\n",
        "        self.bias_linear = self.add_weight(name='bias_linear',\n",
        "                                           shape=(int(self.seq_len),),\n",
        "                                           initializer='uniform',\n",
        "                                           trainable=True)\n",
        "\n",
        "        self.weights_periodic = self.add_weight(name='weight_periodic',\n",
        "                                                shape=(int(self.seq_len),),\n",
        "                                                initializer='uniform',\n",
        "                                                trainable=True)\n",
        "\n",
        "        self.bias_periodic = self.add_weight(name='bias_periodic',\n",
        "                                             shape=(int(self.seq_len),),\n",
        "                                             initializer='uniform',\n",
        "                                             trainable=True)\n",
        "\n",
        "    def call(self, x):\n",
        "        '''Calculate linear and periodic time features'''\n",
        "        x = tf.math.reduce_mean(x[:, :, :4], axis=-1)\n",
        "        time_linear = self.weights_linear * x + self.bias_linear  # Linear time feature\n",
        "        time_linear = tf.expand_dims(time_linear, axis=-1)  # Add dimension (batch, seq_len, 1)\n",
        "\n",
        "        time_periodic = tf.math.sin(tf.multiply(x, self.weights_periodic) + self.bias_periodic)\n",
        "        time_periodic = tf.expand_dims(time_periodic, axis=-1)  # Add dimension (batch, seq_len, 1)\n",
        "        return tf.concat([time_linear, time_periodic], axis=-1)  # shape = (batch, seq_len, 2)\n",
        "\n",
        "    def get_config(self):  # Needed for saving and loading model with custom layer\n",
        "        config = super().get_config().copy()\n",
        "        config.update({'seq_len': self.seq_len})\n",
        "        return config"
      ],
      "metadata": {
        "id": "Aad2MEIA7YFS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SingleAttention(Layer):\n",
        "    def __init__(self, d_k, d_v):\n",
        "        super(SingleAttention, self).__init__()\n",
        "        self.d_k = d_k\n",
        "        self.d_v = d_v\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.query = Dense(self.d_k,\n",
        "                           input_shape=input_shape,\n",
        "                           kernel_initializer='glorot_uniform',\n",
        "                           bias_initializer='glorot_uniform')\n",
        "\n",
        "        self.key = Dense(self.d_k,\n",
        "                         input_shape=input_shape,\n",
        "                         kernel_initializer='glorot_uniform',\n",
        "                         bias_initializer='glorot_uniform')\n",
        "\n",
        "        self.value = Dense(self.d_v,\n",
        "                           input_shape=input_shape,\n",
        "                           kernel_initializer='glorot_uniform',\n",
        "                           bias_initializer='glorot_uniform')\n",
        "\n",
        "    def call(self, inputs):  # inputs = (in_seq, in_seq, in_seq)\n",
        "        q = self.query(inputs[0])\n",
        "        k = self.key(inputs[1])\n",
        "\n",
        "        attn_weights = tf.matmul(q, k, transpose_b=True)\n",
        "        attn_weights = tf.map_fn(lambda x: x / np.sqrt(self.d_k), attn_weights)\n",
        "        attn_weights = tf.nn.softmax(attn_weights, axis=-1)\n",
        "\n",
        "        v = self.value(inputs[2])\n",
        "        attn_out = tf.matmul(attn_weights, v)\n",
        "        return attn_out"
      ],
      "metadata": {
        "id": "yJOMAX5L7foh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiAttention(Layer):\n",
        "    def __init__(self, d_k, d_v, n_heads):\n",
        "        super(MultiAttention, self).__init__()\n",
        "        self.d_k = d_k\n",
        "        self.d_v = d_v\n",
        "        self.n_heads = n_heads\n",
        "        self.attn_heads = list()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        for n in range(self.n_heads):\n",
        "            self.attn_heads.append(SingleAttention(self.d_k, self.d_v))\n",
        "\n",
        "            # input_shape[0]=(batch, seq_len, 7), input_shape[0][-1]=7\n",
        "        self.linear = Dense(input_shape[0][-1],\n",
        "                            input_shape=input_shape,\n",
        "                            kernel_initializer='glorot_uniform',\n",
        "                            bias_initializer='glorot_uniform')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        attn = [self.attn_heads[i](inputs) for i in range(self.n_heads)]\n",
        "        concat_attn = tf.concat(attn, axis=-1)\n",
        "        multi_linear = self.linear(concat_attn)\n",
        "        return multi_linear"
      ],
      "metadata": {
        "id": "cKmN6pTG7fup"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(Layer):\n",
        "    def __init__(self, d_k, d_v, n_heads, ff_dim, dropout=0.1, **kwargs):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.d_k = d_k\n",
        "        self.d_v = d_v\n",
        "        self.n_heads = n_heads\n",
        "        self.ff_dim = ff_dim\n",
        "        self.attn_heads = list()\n",
        "        self.dropout_rate = dropout\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.attn_multi = MultiAttention(self.d_k, self.d_v, self.n_heads)\n",
        "        self.attn_dropout = Dropout(self.dropout_rate)\n",
        "        self.attn_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)\n",
        "\n",
        "        self.ff_conv1D_1 = Conv1D(filters=self.ff_dim, kernel_size=1, activation='relu')\n",
        "        # input_shape[0]=(batch, seq_len, 7), input_shape[0][-1] = 7\n",
        "        self.ff_conv1D_2 = Conv1D(filters=input_shape[0][-1], kernel_size=1)\n",
        "        self.ff_dropout = Dropout(self.dropout_rate)\n",
        "        self.ff_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)\n",
        "\n",
        "    def call(self, inputs):  # inputs = (in_seq, in_seq, in_seq)\n",
        "        attn_layer = self.attn_multi(inputs)\n",
        "        attn_layer = self.attn_dropout(attn_layer)\n",
        "        attn_layer = self.attn_normalize(inputs[0] + attn_layer)\n",
        "\n",
        "        ff_layer = self.ff_conv1D_1(attn_layer)\n",
        "        ff_layer = self.ff_conv1D_2(ff_layer)\n",
        "        ff_layer = self.ff_dropout(ff_layer)\n",
        "        ff_layer = self.ff_normalize(inputs[0] + ff_layer)\n",
        "        return ff_layer\n",
        "\n",
        "    def get_config(self):  # Needed for saving and loading model with custom layer\n",
        "        config = super().get_config().copy()\n",
        "        config.update({'d_k': self.d_k,\n",
        "                       'd_v': self.d_v,\n",
        "                       'n_heads': self.n_heads,\n",
        "                       'ff_dim': self.ff_dim,\n",
        "                       'attn_heads': self.attn_heads,\n",
        "                       'dropout_rate': self.dropout_rate})\n",
        "        return config"
      ],
      "metadata": {
        "id": "XysrapLR7fxh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('solar.csv',)"
      ],
      "metadata": {
        "id": "MWOaxTMy7f0I"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[['Data','Radiation']].iloc[:31000,:]\n",
        "data.set_index('Data',drop=True,inplace=True)\n",
        "data.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "BslftA4-7f5H",
        "outputId": "7ab9dae4-3318-4df1-d896-11e60105151d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  Radiation\n",
              "Data                       \n",
              "12-09-2016 00:00     120.52\n",
              "12-09-2016 00:00     107.32\n",
              "12-09-2016 00:00     144.85\n",
              "12-09-2016 00:00     179.73\n",
              "12-09-2016 00:00     193.00"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f0173a46-e040-431a-b670-946ddb5aac0e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Radiation</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Data</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12-09-2016 00:00</th>\n",
              "      <td>120.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12-09-2016 00:00</th>\n",
              "      <td>107.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12-09-2016 00:00</th>\n",
              "      <td>144.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12-09-2016 00:00</th>\n",
              "      <td>179.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12-09-2016 00:00</th>\n",
              "      <td>193.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0173a46-e040-431a-b670-946ddb5aac0e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f0173a46-e040-431a-b670-946ddb5aac0e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f0173a46-e040-431a-b670-946ddb5aac0e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "input_length = 50\n",
        "output_length = 1\n",
        "test_percentage = 0.2\n",
        "dataset = data['Radiation'].to_numpy()\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "dataset_norm = scaler.fit_transform(dataset.reshape(-1, 1)).flatten()\n",
        "dataset_list = []\n",
        "for i in range(len(dataset) - input_length - output_length):\n",
        "    dataset_list.append(dataset_norm[i:i + input_length + output_length])\n",
        "dataset_list = np.array(dataset_list)\n",
        "trainset = dataset_list[:int(len(dataset_list) * (1 - test_percentage))]\n",
        "testset = dataset_list[int(len(dataset_list) * (1 - test_percentage)):]\n",
        "\n",
        "x_train = trainset[:, :-1]\n",
        "y_train = trainset[:, -1:]\n",
        "x_test = testset[:, :-1]\n",
        "y_test = testset[:, -1:]\n",
        "\n",
        "print('x_train.shape:' + str(x_train.shape))\n",
        "print('y_train.shape:' + str(y_train.shape))\n",
        "print('x_test.shape:' + str(x_test.shape))\n",
        "print('y_test.shape' + str(y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gmoPWDW9M7F",
        "outputId": "a2004b87-1d78-4b14-f17c-a1e0fa8b87b7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train.shape:(24759, 50)\n",
            "y_train.shape:(24759, 1)\n",
            "x_test.shape:(6190, 50)\n",
            "y_test.shape(6190, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 56\n",
        "seq_len = 50\n",
        "\n",
        "d_k = 56\n",
        "d_v = 56\n",
        "n_heads = 4\n",
        "ff_dim = 56"
      ],
      "metadata": {
        "id": "cDyCLDXU9dL-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_embedding_c = Time2Vector(seq_len)\n",
        "attn_layer1_c = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
        "attn_layer2_c = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
        "attn_layer3_c = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
        "\n",
        "in_seq_c = Input(shape=(seq_len, 1))\n",
        "x_c = time_embedding_c(in_seq_c)\n",
        "x_c = Concatenate(axis=-1)([in_seq_c, x_c])\n",
        "x_c = attn_layer1_c((x_c, x_c, x_c))\n",
        "x_c = attn_layer2_c((x_c, x_c, x_c))\n",
        "x_c = attn_layer3_c((x_c, x_c, x_c))\n",
        "x_c = GlobalAveragePooling1D(data_format='channels_first')(x_c)\n",
        "x_c = Dropout(0.1)(x_c)\n",
        "x_c = Dense(64, activation='relu')(x_c)\n",
        "x_c = Dropout(0.1)(x_c)\n",
        "out_c = Dense(1, activation='linear')(x_c)\n",
        "\n",
        "model = Model(inputs=[in_seq_c], outputs=[out_c])\n",
        "\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['mae', 'mape'])\n",
        "\n"
      ],
      "metadata": {
        "id": "__ixkBjm9enR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6uqFDSc9eqW",
        "outputId": "1f0790ae-fc92-4829-8f52-6cfd577568b6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 50, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " time2_vector (Time2Vector)     (None, 50, 2)        200         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 50, 3)        0           ['input_1[0][0]',                \n",
            "                                                                  'time2_vector[0][0]']           \n",
            "                                                                                                  \n",
            " transformer_encoder (Transform  (None, 50, 3)       3770        ['concatenate[0][0]',            \n",
            " erEncoder)                                                       'concatenate[0][0]',            \n",
            "                                                                  'concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " transformer_encoder_1 (Transfo  (None, 50, 3)       3770        ['transformer_encoder[0][0]',    \n",
            " rmerEncoder)                                                     'transformer_encoder[0][0]',    \n",
            "                                                                  'transformer_encoder[0][0]']    \n",
            "                                                                                                  \n",
            " transformer_encoder_2 (Transfo  (None, 50, 3)       3770        ['transformer_encoder_1[0][0]',  \n",
            " rmerEncoder)                                                     'transformer_encoder_1[0][0]',  \n",
            "                                                                  'transformer_encoder_1[0][0]']  \n",
            "                                                                                                  \n",
            " global_average_pooling1d (Glob  (None, 50)          0           ['transformer_encoder_2[0][0]']  \n",
            " alAveragePooling1D)                                                                              \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 50)           0           ['global_average_pooling1d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 64)           3264        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 64)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1)            65          ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 14,839\n",
            "Trainable params: 14,839\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit([x_train],[y_train],\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1hOGVXX9eyL",
        "outputId": "8da21366-5eac-4fdf-e115-ba45dc411f22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "443/443 [==============================] - 89s 170ms/step - loss: 0.0106 - mae: 0.0618 - mape: 18954.5898\n",
            "Epoch 2/100\n",
            "443/443 [==============================] - 72s 162ms/step - loss: 0.0043 - mae: 0.0376 - mape: 8427.6455\n",
            "Epoch 3/100\n",
            "443/443 [==============================] - 71s 160ms/step - loss: 0.0042 - mae: 0.0359 - mape: 7388.2881\n",
            "Epoch 4/100\n",
            "443/443 [==============================] - 72s 163ms/step - loss: 0.0041 - mae: 0.0354 - mape: 7507.5098\n",
            "Epoch 5/100\n",
            "443/443 [==============================] - 72s 162ms/step - loss: 0.0043 - mae: 0.0366 - mape: 7549.0630\n",
            "Epoch 6/100\n",
            "443/443 [==============================] - 72s 164ms/step - loss: 0.0040 - mae: 0.0342 - mape: 6378.3647\n",
            "Epoch 7/100\n",
            "443/443 [==============================] - 71s 160ms/step - loss: 0.0039 - mae: 0.0334 - mape: 6256.4258\n",
            "Epoch 8/100\n",
            "443/443 [==============================] - 72s 164ms/step - loss: 0.0038 - mae: 0.0334 - mape: 6348.8462\n",
            "Epoch 9/100\n",
            "443/443 [==============================] - 72s 162ms/step - loss: 0.0037 - mae: 0.0320 - mape: 5700.7866\n",
            "Epoch 10/100\n",
            "443/443 [==============================] - 74s 166ms/step - loss: 0.0036 - mae: 0.0314 - mape: 5611.9385\n",
            "Epoch 11/100\n",
            "443/443 [==============================] - 71s 160ms/step - loss: 0.0035 - mae: 0.0307 - mape: 5189.4043\n",
            "Epoch 12/100\n",
            "443/443 [==============================] - 70s 158ms/step - loss: 0.0035 - mae: 0.0309 - mape: 5437.7012\n",
            "Epoch 13/100\n",
            "443/443 [==============================] - 70s 158ms/step - loss: 0.0035 - mae: 0.0311 - mape: 5754.5737\n",
            "Epoch 14/100\n",
            "443/443 [==============================] - 72s 162ms/step - loss: 0.0034 - mae: 0.0302 - mape: 5452.2085\n",
            "Epoch 15/100\n",
            "443/443 [==============================] - 72s 163ms/step - loss: 0.0034 - mae: 0.0302 - mape: 5292.3887\n",
            "Epoch 16/100\n",
            "443/443 [==============================] - 71s 161ms/step - loss: 0.0035 - mae: 0.0309 - mape: 5890.7017\n",
            "Epoch 17/100\n",
            "443/443 [==============================] - 70s 158ms/step - loss: 0.0034 - mae: 0.0300 - mape: 5501.9644\n",
            "Epoch 18/100\n",
            "443/443 [==============================] - 71s 160ms/step - loss: 0.0033 - mae: 0.0293 - mape: 5141.3066\n",
            "Epoch 19/100\n",
            "443/443 [==============================] - 71s 161ms/step - loss: 0.0034 - mae: 0.0295 - mape: 5194.2661\n",
            "Epoch 20/100\n",
            "443/443 [==============================] - 73s 164ms/step - loss: 0.0033 - mae: 0.0296 - mape: 5415.2432\n",
            "Epoch 21/100\n",
            "443/443 [==============================] - 73s 164ms/step - loss: 0.0033 - mae: 0.0294 - mape: 5494.2153\n",
            "Epoch 22/100\n",
            "443/443 [==============================] - 73s 164ms/step - loss: 0.0033 - mae: 0.0297 - mape: 5831.1826\n",
            "Epoch 23/100\n",
            "443/443 [==============================] - 71s 161ms/step - loss: 0.0033 - mae: 0.0295 - mape: 5817.5889\n",
            "Epoch 24/100\n",
            "443/443 [==============================] - 69s 156ms/step - loss: 0.0033 - mae: 0.0292 - mape: 5440.4551\n",
            "Epoch 25/100\n",
            "443/443 [==============================] - 69s 156ms/step - loss: 0.0033 - mae: 0.0296 - mape: 5985.6465\n",
            "Epoch 26/100\n",
            "443/443 [==============================] - 69s 156ms/step - loss: 0.0033 - mae: 0.0293 - mape: 5732.9604\n",
            "Epoch 27/100\n",
            "443/443 [==============================] - 70s 158ms/step - loss: 0.0032 - mae: 0.0287 - mape: 5320.3140\n",
            "Epoch 28/100\n",
            "443/443 [==============================] - 68s 155ms/step - loss: 0.0032 - mae: 0.0284 - mape: 5216.5640\n",
            "Epoch 29/100\n",
            "443/443 [==============================] - 69s 155ms/step - loss: 0.0032 - mae: 0.0288 - mape: 5558.3262\n",
            "Epoch 30/100\n",
            "443/443 [==============================] - 68s 153ms/step - loss: 0.0032 - mae: 0.0285 - mape: 5299.5347\n",
            "Epoch 31/100\n",
            "443/443 [==============================] - 69s 156ms/step - loss: 0.0032 - mae: 0.0287 - mape: 5561.8730\n",
            "Epoch 32/100\n",
            "443/443 [==============================] - 69s 156ms/step - loss: 0.0032 - mae: 0.0282 - mape: 5364.2012\n",
            "Epoch 33/100\n",
            "443/443 [==============================] - 66s 150ms/step - loss: 0.0032 - mae: 0.0286 - mape: 5631.9277\n",
            "Epoch 34/100\n",
            "443/443 [==============================] - 70s 158ms/step - loss: 0.0034 - mae: 0.0315 - mape: 7840.6851\n",
            "Epoch 35/100\n",
            "443/443 [==============================] - 67s 152ms/step - loss: 0.0033 - mae: 0.0297 - mape: 6207.1152\n",
            "Epoch 36/100\n",
            "443/443 [==============================] - 68s 153ms/step - loss: 0.0032 - mae: 0.0286 - mape: 5390.1812\n",
            "Epoch 37/100\n",
            "443/443 [==============================] - 67s 150ms/step - loss: 0.0032 - mae: 0.0282 - mape: 5380.2734\n",
            "Epoch 38/100\n",
            "443/443 [==============================] - 66s 150ms/step - loss: 0.0032 - mae: 0.0281 - mape: 5263.8003\n",
            "Epoch 39/100\n",
            "443/443 [==============================] - 66s 149ms/step - loss: 0.0032 - mae: 0.0279 - mape: 5225.1992\n",
            "Epoch 40/100\n",
            "443/443 [==============================] - 66s 150ms/step - loss: 0.0031 - mae: 0.0278 - mape: 5361.1577\n",
            "Epoch 41/100\n",
            "443/443 [==============================] - 66s 150ms/step - loss: 0.0031 - mae: 0.0276 - mape: 5326.6680\n",
            "Epoch 42/100\n",
            "443/443 [==============================] - 67s 151ms/step - loss: 0.0031 - mae: 0.0276 - mape: 5453.7847\n",
            "Epoch 43/100\n",
            "443/443 [==============================] - 68s 153ms/step - loss: 0.0031 - mae: 0.0278 - mape: 5371.9023\n",
            "Epoch 44/100\n",
            "443/443 [==============================] - 69s 156ms/step - loss: 0.0031 - mae: 0.0277 - mape: 5416.8589\n",
            "Epoch 45/100\n",
            "443/443 [==============================] - 68s 152ms/step - loss: 0.0032 - mae: 0.0279 - mape: 5329.2471\n",
            "Epoch 46/100\n",
            "443/443 [==============================] - 68s 153ms/step - loss: 0.0031 - mae: 0.0274 - mape: 5383.9248\n",
            "Epoch 47/100\n",
            "443/443 [==============================] - 68s 153ms/step - loss: 0.0031 - mae: 0.0278 - mape: 5460.6753\n",
            "Epoch 48/100\n",
            "443/443 [==============================] - 67s 152ms/step - loss: 0.0031 - mae: 0.0276 - mape: 5316.0312\n",
            "Epoch 49/100\n",
            "443/443 [==============================] - 76s 171ms/step - loss: 0.0031 - mae: 0.0276 - mape: 5299.3945\n",
            "Epoch 50/100\n",
            "443/443 [==============================] - 70s 158ms/step - loss: 0.0031 - mae: 0.0275 - mape: 5227.4478\n",
            "Epoch 51/100\n",
            "443/443 [==============================] - 68s 154ms/step - loss: 0.0031 - mae: 0.0276 - mape: 5210.7593\n",
            "Epoch 52/100\n",
            "443/443 [==============================] - 67s 151ms/step - loss: 0.0030 - mae: 0.0274 - mape: 5391.9385\n",
            "Epoch 53/100\n",
            "443/443 [==============================] - 68s 153ms/step - loss: 0.0031 - mae: 0.0276 - mape: 5354.9990\n",
            "Epoch 54/100\n",
            "443/443 [==============================] - 67s 152ms/step - loss: 0.0030 - mae: 0.0271 - mape: 5292.7949\n",
            "Epoch 55/100\n",
            "443/443 [==============================] - 66s 150ms/step - loss: 0.0031 - mae: 0.0271 - mape: 5164.3936\n",
            "Epoch 56/100\n",
            "443/443 [==============================] - 67s 151ms/step - loss: 0.0030 - mae: 0.0271 - mape: 5246.2080\n",
            "Epoch 57/100\n",
            "443/443 [==============================] - 67s 151ms/step - loss: 0.0031 - mae: 0.0272 - mape: 5181.8438\n",
            "Epoch 58/100\n",
            "443/443 [==============================] - 68s 154ms/step - loss: 0.0031 - mae: 0.0274 - mape: 5390.7778\n",
            "Epoch 59/100\n",
            "443/443 [==============================] - 69s 155ms/step - loss: 0.0031 - mae: 0.0273 - mape: 5241.5967\n",
            "Epoch 60/100\n",
            "443/443 [==============================] - 68s 153ms/step - loss: 0.0030 - mae: 0.0271 - mape: 5411.5464\n",
            "Epoch 61/100\n",
            "443/443 [==============================] - 68s 154ms/step - loss: 0.0030 - mae: 0.0273 - mape: 5299.3867\n",
            "Epoch 62/100\n",
            "443/443 [==============================] - 68s 153ms/step - loss: 0.0031 - mae: 0.0274 - mape: 5364.6357\n",
            "Epoch 63/100\n",
            "443/443 [==============================] - 67s 152ms/step - loss: 0.0031 - mae: 0.0273 - mape: 5429.6743\n",
            "Epoch 64/100\n",
            "300/443 [===================>..........] - ETA: 21s - loss: 0.0031 - mae: 0.0272 - mape: 5446.0303"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "fig=plt.figure(figsize=(20,5))\n",
        "y_predict = model.predict(x_test)\n",
        "plt.figure(1)\n",
        "plt.plot(y_test, label='real')\n",
        "plt.plot(y_predict, label='prediction')\n",
        "plt.xlabel('MSE Error: {}'.format(mean_squared_error(y_test, y_predict)))\n",
        "plt.legend()\n",
        "plt.title('Prediction result')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5sC-yDhO9e0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig=plt.figure(figsize=(20,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(np.arange(3100,3700),y_predict[3100:3700],label='Radiation, predicted')\n",
        "plt.plot(np.arange(3100,3700),y_test[3100:3700],label=\"Radiation\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "C7hbMe5z9e3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "score = metrics.mean_squared_error(y_test, y_predict)\n",
        "print(\"Final score (MSE): {}\".format(score))"
      ],
      "metadata": {
        "id": "qX1FbfXkD7GW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "MAE = mean_absolute_error(y_test, y_predict)\n",
        "print(\"Final score (MAE): {}\".format(MAE))"
      ],
      "metadata": {
        "id": "Z2EINDdDD7JV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Measure RMSE error.  RMSE is common for regression.\n",
        "score = np.sqrt(metrics.mean_squared_error(y_test, y_predict))\n",
        "print(\"Final score (RMSE): {}\".format(score))"
      ],
      "metadata": {
        "id": "_-ZEjTkaD7MQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "R2 = r2_score(y_test, y_predict, multioutput='variance_weighted')\n",
        "print(\"Final score (R2): {}\".format(R2))"
      ],
      "metadata": {
        "id": "ZqYM_6KmFL1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import skew\n",
        "from scipy.stats import kurtosis\n",
        "\n",
        "print(\"Final score (skew):\")\n",
        "print(skew(y_predict, axis=0, bias=True))"
      ],
      "metadata": {
        "id": "Mug7C3o_FTYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Final score (kurtosis):\")\n",
        "print(kurtosis(y_predict, axis=0, bias=True))"
      ],
      "metadata": {
        "id": "Nwzp2r96FTca"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}