{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransformerModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMs64CJGKJdvEaTlv2KhoPJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sujal-vajire/Machine-learning-models/blob/main/TransformerModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlvqhpOy7V5N",
        "outputId": "c0d47461-5df2-4f67-acf2-9bcd768a5e99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version: 2.8.2\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "print('Tensorflow version: {}'.format(tf.__version__))\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Time2Vector(Layer):\n",
        "    def __init__(self, seq_len, **kwargs):\n",
        "        super(Time2Vector, self).__init__()\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        '''Initialize weights and biases with shape (batch, seq_len)'''\n",
        "        self.weights_linear = self.add_weight(name='weight_linear',\n",
        "                                              shape=(int(self.seq_len),),\n",
        "                                              initializer='uniform',\n",
        "                                              trainable=True)\n",
        "\n",
        "        self.bias_linear = self.add_weight(name='bias_linear',\n",
        "                                           shape=(int(self.seq_len),),\n",
        "                                           initializer='uniform',\n",
        "                                           trainable=True)\n",
        "\n",
        "        self.weights_periodic = self.add_weight(name='weight_periodic',\n",
        "                                                shape=(int(self.seq_len),),\n",
        "                                                initializer='uniform',\n",
        "                                                trainable=True)\n",
        "\n",
        "        self.bias_periodic = self.add_weight(name='bias_periodic',\n",
        "                                             shape=(int(self.seq_len),),\n",
        "                                             initializer='uniform',\n",
        "                                             trainable=True)\n",
        "\n",
        "    def call(self, x):\n",
        "        '''Calculate linear and periodic time features'''\n",
        "        x = tf.math.reduce_mean(x[:, :, :4], axis=-1)\n",
        "        time_linear = self.weights_linear * x + self.bias_linear  # Linear time feature\n",
        "        time_linear = tf.expand_dims(time_linear, axis=-1)  # Add dimension (batch, seq_len, 1)\n",
        "\n",
        "        time_periodic = tf.math.sin(tf.multiply(x, self.weights_periodic) + self.bias_periodic)\n",
        "        time_periodic = tf.expand_dims(time_periodic, axis=-1)  # Add dimension (batch, seq_len, 1)\n",
        "        return tf.concat([time_linear, time_periodic], axis=-1)  # shape = (batch, seq_len, 2)\n",
        "\n",
        "    def get_config(self):  # Needed for saving and loading model with custom layer\n",
        "        config = super().get_config().copy()\n",
        "        config.update({'seq_len': self.seq_len})\n",
        "        return config"
      ],
      "metadata": {
        "id": "Aad2MEIA7YFS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SingleAttention(Layer):\n",
        "    def __init__(self, d_k, d_v):\n",
        "        super(SingleAttention, self).__init__()\n",
        "        self.d_k = d_k\n",
        "        self.d_v = d_v\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.query = Dense(self.d_k,\n",
        "                           input_shape=input_shape,\n",
        "                           kernel_initializer='glorot_uniform',\n",
        "                           bias_initializer='glorot_uniform')\n",
        "\n",
        "        self.key = Dense(self.d_k,\n",
        "                         input_shape=input_shape,\n",
        "                         kernel_initializer='glorot_uniform',\n",
        "                         bias_initializer='glorot_uniform')\n",
        "\n",
        "        self.value = Dense(self.d_v,\n",
        "                           input_shape=input_shape,\n",
        "                           kernel_initializer='glorot_uniform',\n",
        "                           bias_initializer='glorot_uniform')\n",
        "\n",
        "    def call(self, inputs):  # inputs = (in_seq, in_seq, in_seq)\n",
        "        q = self.query(inputs[0])\n",
        "        k = self.key(inputs[1])\n",
        "\n",
        "        attn_weights = tf.matmul(q, k, transpose_b=True)\n",
        "        attn_weights = tf.map_fn(lambda x: x / np.sqrt(self.d_k), attn_weights)\n",
        "        attn_weights = tf.nn.softmax(attn_weights, axis=-1)\n",
        "\n",
        "        v = self.value(inputs[2])\n",
        "        attn_out = tf.matmul(attn_weights, v)\n",
        "        return attn_out"
      ],
      "metadata": {
        "id": "yJOMAX5L7foh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiAttention(Layer):\n",
        "    def __init__(self, d_k, d_v, n_heads):\n",
        "        super(MultiAttention, self).__init__()\n",
        "        self.d_k = d_k\n",
        "        self.d_v = d_v\n",
        "        self.n_heads = n_heads\n",
        "        self.attn_heads = list()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        for n in range(self.n_heads):\n",
        "            self.attn_heads.append(SingleAttention(self.d_k, self.d_v))\n",
        "\n",
        "            # input_shape[0]=(batch, seq_len, 7), input_shape[0][-1]=7\n",
        "        self.linear = Dense(input_shape[0][-1],\n",
        "                            input_shape=input_shape,\n",
        "                            kernel_initializer='glorot_uniform',\n",
        "                            bias_initializer='glorot_uniform')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        attn = [self.attn_heads[i](inputs) for i in range(self.n_heads)]\n",
        "        concat_attn = tf.concat(attn, axis=-1)\n",
        "        multi_linear = self.linear(concat_attn)\n",
        "        return multi_linear"
      ],
      "metadata": {
        "id": "cKmN6pTG7fup"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(Layer):\n",
        "    def __init__(self, d_k, d_v, n_heads, ff_dim, dropout=0.1, **kwargs):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.d_k = d_k\n",
        "        self.d_v = d_v\n",
        "        self.n_heads = n_heads\n",
        "        self.ff_dim = ff_dim\n",
        "        self.attn_heads = list()\n",
        "        self.dropout_rate = dropout\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.attn_multi = MultiAttention(self.d_k, self.d_v, self.n_heads)\n",
        "        self.attn_dropout = Dropout(self.dropout_rate)\n",
        "        self.attn_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)\n",
        "\n",
        "        self.ff_conv1D_1 = Conv1D(filters=self.ff_dim, kernel_size=1, activation='relu')\n",
        "        # input_shape[0]=(batch, seq_len, 7), input_shape[0][-1] = 7\n",
        "        self.ff_conv1D_2 = Conv1D(filters=input_shape[0][-1], kernel_size=1)\n",
        "        self.ff_dropout = Dropout(self.dropout_rate)\n",
        "        self.ff_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)\n",
        "\n",
        "    def call(self, inputs):  # inputs = (in_seq, in_seq, in_seq)\n",
        "        attn_layer = self.attn_multi(inputs)\n",
        "        attn_layer = self.attn_dropout(attn_layer)\n",
        "        attn_layer = self.attn_normalize(inputs[0] + attn_layer)\n",
        "\n",
        "        ff_layer = self.ff_conv1D_1(attn_layer)\n",
        "        ff_layer = self.ff_conv1D_2(ff_layer)\n",
        "        ff_layer = self.ff_dropout(ff_layer)\n",
        "        ff_layer = self.ff_normalize(inputs[0] + ff_layer)\n",
        "        return ff_layer\n",
        "\n",
        "    def get_config(self):  # Needed for saving and loading model with custom layer\n",
        "        config = super().get_config().copy()\n",
        "        config.update({'d_k': self.d_k,\n",
        "                       'd_v': self.d_v,\n",
        "                       'n_heads': self.n_heads,\n",
        "                       'ff_dim': self.ff_dim,\n",
        "                       'attn_heads': self.attn_heads,\n",
        "                       'dropout_rate': self.dropout_rate})\n",
        "        return config"
      ],
      "metadata": {
        "id": "XysrapLR7fxh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('dataset1.csv',)"
      ],
      "metadata": {
        "id": "MWOaxTMy7f0I"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[['Data','Radiation']].iloc[:31000,:]\n",
        "data.set_index('Data',drop=True,inplace=True)\n",
        "data.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "BslftA4-7f5H",
        "outputId": "fb1fa348-b008-4353-cefa-a0ab4cc5e6db"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  Radiation\n",
              "Data                       \n",
              "12-09-2016 00:00     120.52\n",
              "12-09-2016 00:00     107.32\n",
              "12-09-2016 00:00     144.85\n",
              "12-09-2016 00:00     179.73\n",
              "12-09-2016 00:00     193.00"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-01f68146-60fe-4c2d-9e86-b70decc6e11c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Radiation</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Data</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12-09-2016 00:00</th>\n",
              "      <td>120.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12-09-2016 00:00</th>\n",
              "      <td>107.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12-09-2016 00:00</th>\n",
              "      <td>144.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12-09-2016 00:00</th>\n",
              "      <td>179.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12-09-2016 00:00</th>\n",
              "      <td>193.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01f68146-60fe-4c2d-9e86-b70decc6e11c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-01f68146-60fe-4c2d-9e86-b70decc6e11c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-01f68146-60fe-4c2d-9e86-b70decc6e11c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "input_length = 50\n",
        "output_length = 1\n",
        "test_percentage = 0.2\n",
        "dataset = data['Radiation'].to_numpy()\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "dataset_norm = scaler.fit_transform(dataset.reshape(-1, 1)).flatten()\n",
        "dataset_list = []\n",
        "for i in range(len(dataset) - input_length - output_length):\n",
        "    dataset_list.append(dataset_norm[i:i + input_length + output_length])\n",
        "dataset_list = np.array(dataset_list)\n",
        "trainset = dataset_list[:int(len(dataset_list) * (1 - test_percentage))]\n",
        "testset = dataset_list[int(len(dataset_list) * (1 - test_percentage)):]\n",
        "\n",
        "x_train = trainset[:, :-1]\n",
        "y_train = trainset[:, -1:]\n",
        "x_test = testset[:, :-1]\n",
        "y_test = testset[:, -1:]\n",
        "\n",
        "print('x_train.shape:' + str(x_train.shape))\n",
        "print('y_train.shape:' + str(y_train.shape))\n",
        "print('x_test.shape:' + str(x_test.shape))\n",
        "print('y_test.shape' + str(y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gmoPWDW9M7F",
        "outputId": "cd84f899-76b0-4aea-cead-1a5c3392a5f2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train.shape:(24519, 350)\n",
            "y_train.shape:(24519, 1)\n",
            "x_test.shape:(6130, 350)\n",
            "y_test.shape(6130, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "seq_len = 50\n",
        "\n",
        "d_k = 256\n",
        "d_v = 256\n",
        "n_heads = 12\n",
        "ff_dim = 256"
      ],
      "metadata": {
        "id": "cDyCLDXU9dL-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_embedding_c = Time2Vector(seq_len)\n",
        "attn_layer1_c = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
        "attn_layer2_c = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
        "attn_layer3_c = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
        "\n",
        "in_seq_c = Input(shape=(seq_len, 1))\n",
        "x_c = time_embedding_c(in_seq_c)\n",
        "x_c = Concatenate(axis=-1)([in_seq_c, x_c])\n",
        "x_c = attn_layer1_c((x_c, x_c, x_c))\n",
        "x_c = attn_layer2_c((x_c, x_c, x_c))\n",
        "x_c = attn_layer3_c((x_c, x_c, x_c))\n",
        "x_c = GlobalAveragePooling1D(data_format='channels_first')(x_c)\n",
        "x_c = Dropout(0.1)(x_c)\n",
        "x_c = Dense(64, activation='relu')(x_c)\n",
        "x_c = Dropout(0.1)(x_c)\n",
        "out_c = Dense(1, activation='linear')(x_c)\n",
        "\n",
        "model = Model(inputs=[in_seq_c], outputs=[out_c])\n",
        "\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['mae', 'mape'])\n",
        "\n"
      ],
      "metadata": {
        "id": "__ixkBjm9enR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6uqFDSc9eqW",
        "outputId": "0e911d75-7ab9-445e-a5ec-65d832fd36bc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 350, 1)]     0           []                               \n",
            "                                                                                                  \n",
            " time2_vector_1 (Time2Vector)   (None, 350, 2)       1400        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 350, 3)       0           ['input_2[0][0]',                \n",
            "                                                                  'time2_vector_1[0][0]']         \n",
            "                                                                                                  \n",
            " transformer_encoder_3 (Transfo  (None, 350, 3)      47890       ['concatenate_1[0][0]',          \n",
            " rmerEncoder)                                                     'concatenate_1[0][0]',          \n",
            "                                                                  'concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " transformer_encoder_4 (Transfo  (None, 350, 3)      47890       ['transformer_encoder_3[0][0]',  \n",
            " rmerEncoder)                                                     'transformer_encoder_3[0][0]',  \n",
            "                                                                  'transformer_encoder_3[0][0]']  \n",
            "                                                                                                  \n",
            " transformer_encoder_5 (Transfo  (None, 350, 3)      47890       ['transformer_encoder_4[0][0]',  \n",
            " rmerEncoder)                                                     'transformer_encoder_4[0][0]',  \n",
            "                                                                  'transformer_encoder_4[0][0]']  \n",
            "                                                                                                  \n",
            " global_average_pooling1d_1 (Gl  (None, 350)         0           ['transformer_encoder_5[0][0]']  \n",
            " obalAveragePooling1D)                                                                            \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 350)          0           ['global_average_pooling1d_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 64)           22464       ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 64)           0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 1)            65          ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 167,599\n",
            "Trainable params: 167,599\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit([x_train],[y_train],\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1hOGVXX9eyL",
        "outputId": "1ad7020c-4507-4c3a-fdfe-7a9330c02096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5sC-yDhO9e0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "C7hbMe5z9e3X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}